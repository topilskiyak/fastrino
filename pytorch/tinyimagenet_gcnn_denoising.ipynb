{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTCTqc6L1tnL"
   },
   "source": [
    "# Pytorch Tiny Imagenet GCNN Denoising\n",
    "\n",
    "Resources:\n",
    "- [Tiny Imagenet](https://tiny-imagenet.herokuapp.com/)\n",
    "- [GCNN Paper]()\n",
    "- [Building KNN index](https://github.com/rusty1s/pytorch_cluster)\n",
    "\n",
    "Notes:\n",
    "- [unfold](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.unfold) / [Fold](https://pytorch.org/docs/stable/nn.html#torch.nn.Fold) / [how-to-use](https://stackoverflow.com/questions/53972159/how-does-pytorchs-fold-and-unfold-work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCNN Limitations\n",
    "\n",
    "GCNN hits GPU memory limitations pretty hard.\n",
    "\n",
    "Main culprit is probably the intermediate graph convolution aggregation tensor of size BHWKCC:\n",
    "- B - batch\n",
    "- HW - height-width\n",
    "- K - number of nearest neighbours taken\n",
    "- CC - matrix converting hidden features to new hidden features\n",
    "\n",
    "In the original paper: H,W = 32, K = 8, C = 66, HWKCC $\\sim 4 \\cdot 10^7$.  \n",
    "Note that these types of tensors are used 10 times in the model, so the overall impact is $\\sim 4 \\cdot 10^8$. This means that even 16 is already a large batch size - these tensors will have $\\sim 6.4 \\cdot 10^9$ parameters, so approx 6GB. In comparison, the memory limit of the GPUs used is 10-12GB.\n",
    "\n",
    "So we have to balance the size of hidden features and the batch size.\n",
    "\n",
    "Another problem is that each batch itself trains very slowly, so going throw the whole training/testing/validation datasets takes very long.\n",
    "\n",
    "\n",
    "Results on a Tesla K80:  \n",
    "\n",
    "| hidden | max batch | opt batch | train (1b) | eval (1b) |\n",
    "| ------ | --------- | --------- | ---------- | --------- |\n",
    "|   66   |         8 |         - |       2.0s |      1.5s |\n",
    "|   48   |        16 |         - |       1.8s |      1.2s |\n",
    "|   24   |        56 |        48 |       2.1s |      1.2s |\n",
    "|   12   |       160 |         - |       3.9s |      2.2s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rUGBwYqsJlO2"
   },
   "source": [
    "### Comet_ML\n",
    "\n",
    "NOTE: comet_ml is not installed in google colab by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5374,
     "status": "ok",
     "timestamp": 1579361784860,
     "user": {
      "displayName": "Artem Topilskiy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDI-avhqJwgahop5KKKRe_5xk0jO9ug8NdpSOxX=s64",
      "userId": "16398220761843505060"
     },
     "user_tz": -180
    },
    "id": "PCTm3b7hoN12",
    "outputId": "af0f5b97-b83a-4227-b1bf-4be1d69700a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
      "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (3.0.2)\n",
      "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.56.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from comet_ml) (1.11.0)\n",
      "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.22.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
      "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
      "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.14)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml) (42.0.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml) (0.15.6)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema<3.1.0,>=2.6.0->comet_ml) (19.3.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.18.4->comet_ml) (2.6)\n",
      "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Id--7c5WJnW1"
   },
   "outputs": [],
   "source": [
    "comet_ml_settings = dict(\n",
    "    api_key=None,\n",
    "    project_name='fastrino',\n",
    "    workspace=None,\n",
    ")\n",
    "\n",
    "assert comet_ml_settings[\"api_key\"] is not None, \"set your comet_ml api_key\"\n",
    "assert comet_ml_settings[\"workspace\"] is not None, \"set your comet_ml workspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM-tCnsOoQJS"
   },
   "outputs": [],
   "source": [
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53uX3FGs2JMt"
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7977,
     "status": "ok",
     "timestamp": 1579361787495,
     "user": {
      "displayName": "Artem Topilskiy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDI-avhqJwgahop5KKKRe_5xk0jO9ug8NdpSOxX=s64",
      "userId": "16398220761843505060"
     },
     "user_tz": -180
    },
    "id": "XtXla-9osExx",
    "outputId": "b2727400-d19a-4065-b90f-d6c7a295af14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-cluster in /home/atopilskiy/.local/lib/python3.6/site-packages (1.4.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.17.3)\n",
      "Requirement already satisfied: opencv-python in /home/atopilskiy/.local/lib/python3.6/site-packages (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.3)\n",
      "Requirement already satisfied: psutil in /home/atopilskiy/.local/lib/python3.6/site-packages (5.6.7)\n"
     ]
    }
   ],
   "source": [
    "# knn_graph\n",
    "!pip install --user torch-cluster\n",
    "\n",
    "# cv2\n",
    "!pip install --user opencv-python\n",
    "\n",
    "# debug\n",
    "!pip install --user psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqjArkmIjKA1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch_cluster import knn_graph\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8386,
     "status": "ok",
     "timestamp": 1579361787929,
     "user": {
      "displayName": "Artem Topilskiy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDI-avhqJwgahop5KKKRe_5xk0jO9ug8NdpSOxX=s64",
      "userId": "16398220761843505060"
     },
     "user_tz": -180
    },
    "id": "Jo4Q__aSOFZD",
    "outputId": "3ffa9aa9-983e-425d-9d31-1fa3673a5958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torchmemdebug.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile torchmemdebug.py\n",
    "\n",
    "# https://discuss.pytorch.org/t/how-pytorch-releases-variable-garbage/7277/2\n",
    "\n",
    "import gc\n",
    "import psutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "def mem_report():\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj):\n",
    "            print(type(obj), obj.size())\n",
    "    \n",
    "def cpu_stats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RomR9_xxOsW6"
   },
   "outputs": [],
   "source": [
    "import torchmemdebug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvvEmsfW2C7q"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rwh2NDcK1KT"
   },
   "source": [
    "Download TinyImagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7h2XduHK48W"
   },
   "outputs": [],
   "source": [
    "if not Path('tiny-imagenet-200.zip').exists():\n",
    "    !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "    !unzip -q tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRkUzht-KYbE"
   },
   "source": [
    "Full TinyImagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHVSPWQyL835"
   },
   "outputs": [],
   "source": [
    "TINY_IMAGENET_DIR = Path('tiny-imagenet-200')\n",
    "TINY_IMAGENET_PARTS = ['train', 'test', 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HGzyB_pKCUY"
   },
   "outputs": [],
   "source": [
    "def imgdir_to_array(imgdir, take_part=0.1):\n",
    "    images = []\n",
    "    for path in imgdir.iterdir():\n",
    "        img = cv2.imread(str(path))\n",
    "        images.append(img)\n",
    "    stacked = np.stack(images)\n",
    "    take_every = max(1, int(1 / take_part))\n",
    "    taken = stacked[::take_every]\n",
    "    return taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fV8NnJWUIvq_"
   },
   "outputs": [],
   "source": [
    "def dump_cache(source_dict, cache_suffix):\n",
    "    for part, array in source_dict.items():\n",
    "        np.save(part + cache_suffix, array)\n",
    "    print(\"Dumped to cache: \" + cache_suffix)    \n",
    "\n",
    "\n",
    "def load_cache(target_dict, cache_suffix):\n",
    "    for part in TINY_IMAGENET_PARTS:\n",
    "        target_dict[part] = np.load(part + cache_suffix + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLCHwyXTKH4l"
   },
   "outputs": [],
   "source": [
    "class TinyImagenet:\n",
    "    CACHE_SUFFIX = '_full'\n",
    "\n",
    "    def __init__(self, use_cache=True):\n",
    "        self._load_arrays(use_cache)\n",
    "    \n",
    "    def _load_arrays(self, use_cache):\n",
    "        self.arrays = {}\n",
    "        if use_cache:\n",
    "            load_cache(self.arrays, self.CACHE_SUFFIX)\n",
    "            return\n",
    "        \n",
    "        self._load_train()\n",
    "        self._load_test()\n",
    "        self._load_val()\n",
    "\n",
    "        dump_cache(self.arrays, self.CACHE_SUFFIX)\n",
    "    \n",
    "    def _load_train(self):\n",
    "        train_dir = TINY_IMAGENET_DIR / 'train'\n",
    "\n",
    "        image_arrays = []\n",
    "        for imgdir in train_dir.iterdir():\n",
    "            image_arrays.append(imgdir_to_array(imgdir / 'images'))\n",
    "        self.arrays['train'] = np.concatenate(image_arrays, axis=0)\n",
    "\n",
    "    def _load_test(self):\n",
    "        self.arrays['test'] = imgdir_to_array(TINY_IMAGENET_DIR / 'test' / 'images')\n",
    "    \n",
    "    def _load_val(self):\n",
    "        self.arrays['val'] = imgdir_to_array(TINY_IMAGENET_DIR / 'val' / 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DR2pPOjdqfhX"
   },
   "outputs": [],
   "source": [
    "def test_ti(use_cache):\n",
    "    ti = TinyImagenet(use_cache)\n",
    "\n",
    "    for name, arr in ti.arrays.items():\n",
    "        print(name + '\\t', arr.shape)\n",
    "    \n",
    "    for img in [arr[100] for arr in ti.arrays.values()]:\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWp1qG2YrIkH"
   },
   "outputs": [],
   "source": [
    "#test_ti(False)\n",
    "#test_ti(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mC3L0k08-c8P"
   },
   "outputs": [],
   "source": [
    "def print_statistics():\n",
    "    ti = TinyImagenet(use_cache=True)\n",
    "    ars = ti.arrays['train'] / 255\n",
    "    print('mean=', ars.mean(axis=(0,2,3)))\n",
    "    ars -= ars.mean(axis=(0,2,3))[np.newaxis, :, np.newaxis, np.newaxis]\n",
    "    ars **= 2\n",
    "    print('std=', ars.mean(axis=(0,2,3)))\n",
    "\n",
    "#print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0EXsUjIKh06"
   },
   "source": [
    "TinyImagenet split into patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bwmhd21srS07"
   },
   "outputs": [],
   "source": [
    "def split_into_patches(array, kernel_size=32, stride=32):\n",
    "    _, max_x, max_y, _ = array.shape\n",
    "    patches = []\n",
    "    for x_end in range(kernel_size, max_x + 1, stride):\n",
    "        for y_end in range(kernel_size, max_y + 1, stride):\n",
    "            x_start = x_end - kernel_size\n",
    "            y_start = y_end - kernel_size\n",
    "            patch = array[:, x_start:x_end, y_start:y_end, :]\n",
    "            patches.append(patch)\n",
    "    return np.concatenate(patches, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7usyQuXZKOhO"
   },
   "outputs": [],
   "source": [
    "class ArrayDataset(Dataset):\n",
    "    def __init__(self, array, transform):\n",
    "        self.array = array\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.array)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.array[index])\n",
    "        \n",
    "\n",
    "class TinyImagenetPatches:\n",
    "    CACHE_SUFFIX = '_patches'\n",
    "\n",
    "    def __init__(self, tiny_imagenet=None, initial_transform=None):\n",
    "        self._make_patches(tiny_imagenet)\n",
    "        self._make_datasets(initial_transform)\n",
    "    \n",
    "    def _make_patches(self, tiny_imagenet):\n",
    "        self.patches = {}\n",
    "        if tiny_imagenet is None:\n",
    "            load_cache(self.patches, self.CACHE_SUFFIX)\n",
    "            return\n",
    "        \n",
    "        for name, array in tiny_imagenet.arrays.items():\n",
    "            self.patches[name] = split_into_patches(array)\n",
    "\n",
    "        dump_cache(self.patches, self.CACHE_SUFFIX)\n",
    "    \n",
    "    def _make_datasets(self, transform):\n",
    "        if transform is None:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToTensor(),  # ALSO IMPLICITLY DIVIDES BY 255 AND DOES HWC->CHW\n",
    "                transforms.Normalize(mean=(0.39750364, 0.44806704, 0.48023694), \n",
    "                                      std=(0.28158993, 0.26886327, 0.27643643))\n",
    "            ])\n",
    "        \n",
    "        self.datasets = {}\n",
    "        for name, patches in self.patches.items():\n",
    "            self.datasets[name] = ArrayDataset(patches, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kX_eNfWlRWWE"
   },
   "outputs": [],
   "source": [
    "def test_tip(use_cache):\n",
    "    if use_cache:\n",
    "        tip = TinyImagenetPatches()\n",
    "    else:\n",
    "        ti = TinyImagenet(use_cache=True)\n",
    "        tip = TinyImagenetPatches(ti)\n",
    "\n",
    "    for name, arr in tip.patches.items():\n",
    "        print(name + '\\t', arr.shape)\n",
    "    \n",
    "    for img in [arr[100] for arr in tip.patches.values()]:\n",
    "        plt.imshow(img)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WuZ1Mw8quVB-"
   },
   "outputs": [],
   "source": [
    "#test_tip(use_cache=False)\n",
    "#test_tip(use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DiCSNHg9Kkxf"
   },
   "source": [
    "Denoising Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tq0LwjkzrSDE"
   },
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, dataset, noise_std):\n",
    "        self.dataset = dataset\n",
    "        self.noise_std = noise_std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.dataset[index]\n",
    "        noise = self.noise_std * torch.randn_like(image)\n",
    "        noisy_image = image + noise\n",
    "        return noisy_image, noise\n",
    "\n",
    "\n",
    "class TinyImagenetPatchesDenoising:\n",
    "    def __init__(self, noise_std, tiny_imagenet=None):\n",
    "        if tiny_imagenet is None:\n",
    "            tiny_imagenet = TinyImagenetPatches()\n",
    "        self.tiny_imagenet = tiny_imagenet\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "        self._make_datasets()\n",
    "\n",
    "    def _make_datasets(self):\n",
    "        self.datasets = {}\n",
    "        for name, dataset in self.tiny_imagenet.datasets.items():\n",
    "            self.datasets[name] = DenoisingDataset(dataset, self.noise_std)\n",
    "    \n",
    "    def get_loaders(self, batch_size):\n",
    "        train = torch.utils.data.DataLoader(\n",
    "            self.datasets['train'], batch_size=batch_size, shuffle=True)\n",
    "        test = torch.utils.data.DataLoader(\n",
    "            self.datasets['test'], batch_size=batch_size, shuffle=False)\n",
    "        val = torch.utils.data.DataLoader(\n",
    "            self.datasets['val'], batch_size=batch_size, shuffle=False)\n",
    "        return train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_mx3xAZ_aGE"
   },
   "outputs": [],
   "source": [
    "def test_tipd():\n",
    "    loaders = TinyImagenetPatchesDenoising(0.1).get_loaders(128)\n",
    "\n",
    "    for name, loader in zip(TINY_IMAGENET_PARTS, loaders):\n",
    "        batch_image, batch_noise = next(iter(loader))\n",
    "        print(name)\n",
    "        print(batch_image.shape, f'mean={batch_image.mean()}', f'std={batch_image.std()}')\n",
    "        print(batch_noise.shape, f'mean={batch_noise.mean()}', f'std={batch_noise.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlakD3ngAocg"
   },
   "outputs": [],
   "source": [
    "#test_tipd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYvbJe4uuGnu"
   },
   "source": [
    "Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NpRGuyXpuJ6b"
   },
   "outputs": [],
   "source": [
    "def cache_exists():\n",
    "    path = Path('.')\n",
    "    for cache_suffix in [TinyImagenet.CACHE_SUFFIX, TinyImagenetPatches.CACHE_SUFFIX]:\n",
    "        for part in TINY_IMAGENET_PARTS:\n",
    "            file_ = path / (part + cache_suffix + '.npy')\n",
    "            if not file_.exists():\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "if not cache_exists():\n",
    "    ti = TinyImagenet(use_cache=False)\n",
    "    TinyImagenetPatches(ti)\n",
    "    assert cache_exists()\n",
    "    os._exit(0)  # Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPVcnuOa5msh"
   },
   "source": [
    "### DnCNN Model\n",
    "\n",
    "[Paper](https://arxiv.org/abs/1608.03981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CLxV4q1BWVE"
   },
   "outputs": [],
   "source": [
    "class DnCNNBlock(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super(DnCNNBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_, out, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, num_blocks=4, input_image_shape=[3, 32, 32], block_num_filters=64):\n",
    "        super(DnCNN, self).__init__()\n",
    "        \n",
    "        self.name = f'dncnn'\n",
    "        \n",
    "        num_input_channels, *_ = input_image_shape\n",
    "\n",
    "        self.input_convrelu = nn.Sequential(\n",
    "            nn.Conv2d(num_input_channels, block_num_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        blocks = [DnCNNBlock(block_num_filters, block_num_filters) for _ in range(num_blocks)]\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "        self.output_conv = nn.Conv2d(block_num_filters, num_input_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_ = self.input_convrelu(x)\n",
    "        blocks = self.blocks(input_)\n",
    "        output = self.output_conv(blocks)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6TGEQtfp2Sa"
   },
   "outputs": [],
   "source": [
    "def get_dncnn_model():\n",
    "    model = DnCNN().to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iu73dPj9tiE3"
   },
   "source": [
    "### GCNN Model\n",
    "\n",
    "[Paper](https://arxiv.org/abs/1905.12281)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c11wKYwUPhb4"
   },
   "source": [
    "Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLltAdWlSRic"
   },
   "outputs": [],
   "source": [
    "class NonLocalGraph(nn.Module):\n",
    "    def __init__(self, features, near_neigh):\n",
    "        super(NonLocalGraph, self).__init__()\n",
    "        self.features = features\n",
    "        self.k = near_neigh\n",
    "        self._init_neightbours()\n",
    "    \n",
    "    def _init_neightbours(self):\n",
    "        features = self.features.permute((0, 2, 3, 1))\n",
    "        b, h, w, c = features.shape\n",
    "        k = self.k\n",
    "\n",
    "        flat_features = features.reshape((-1, c))\n",
    "\n",
    "        batch_indices = torch.arange(b, device=device)\\\n",
    "                             .unsqueeze(-1).unsqueeze(-1).expand((b, h, w))\\\n",
    "                             .reshape(-1)\n",
    "        \n",
    "        flat_nn = knn_graph(flat_features, batch=batch_indices, k=k, loop=False)\n",
    "        flat_nn = flat_nn[0, :]  # assume that we always find k neighbours\n",
    "        \n",
    "        self.neighbours = flat_nn.reshape((b, h, w, k))\n",
    "    \n",
    "    def get_neighbours(self):\n",
    "        return self.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jky7UvqR-PMu"
   },
   "outputs": [],
   "source": [
    "class AggregationWeights(nn.Module):\n",
    "    def __init__(self, input_features, output_features, leakyrelu_alpha):\n",
    "        super(AggregationWeights, self).__init__()\n",
    "        self.c_in = input_features\n",
    "        self.c_out = output_features\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(input_features, input_features),\n",
    "            nn.LeakyReLU(leakyrelu_alpha),\n",
    "            nn.Linear(input_features, output_features * input_features, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_):\n",
    "        b, h, w, k, c_in = input_.shape\n",
    "        c_out = self.c_out\n",
    "\n",
    "        output = self.output(input_)\n",
    "        return output.reshape((b, h, w, k, c_out, c_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzkpsOIqZQGz"
   },
   "outputs": [],
   "source": [
    "class NonLocalAggregation(nn.Module):\n",
    "    def __init__(self, input_features, output_features, leakyrelu_alpha):\n",
    "        super(NonLocalAggregation, self).__init__()\n",
    "        self.linear = nn.Linear(input_features, output_features)\n",
    "        self.aggregation_weights = AggregationWeights(input_features, output_features, leakyrelu_alpha)\n",
    "        self.activation = nn.LeakyReLU(leakyrelu_alpha)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        input_, non_local_graph = input_\n",
    "        input_ = input_.permute((0, 2, 3, 1))\n",
    "\n",
    "        b, h, w, c = input_.shape\n",
    "        k = non_local_graph.k\n",
    "\n",
    "        indices = non_local_graph.get_neighbours()\n",
    "        indices = indices.reshape(-1).unsqueeze(-1).expand((-1, c))\n",
    "        gathered = torch.gather(input_.reshape((-1, c)), 0, indices)\n",
    "        neighbours = gathered.reshape((b, h, w, k, c))\n",
    "\n",
    "        delta = neighbours - input_.unsqueeze(-2)\n",
    "        weights = self.aggregation_weights(delta)\n",
    "\n",
    "        weighted_neighbours = torch.matmul(\n",
    "            weights, neighbours.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        aggregation = weighted_neighbours.mean(-2)\n",
    "        linear = self.linear(input_)\n",
    "\n",
    "        output = self.activation(aggregation + linear)\n",
    "        return output.permute((0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxPvyVsoPjTi"
   },
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_features, output_features, near_neigh, leakyrelu_alpha):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "\n",
    "        self.near_neigh = near_neigh\n",
    "\n",
    "        self.conv1x1 = nn.Conv2d(input_features, output_features, kernel_size=1, padding=0)\n",
    "        self.conv3x3 = nn.Conv2d(input_features, output_features, kernel_size=3, padding=1)\n",
    "        self.non_local_aggregation = NonLocalAggregation(input_features, output_features, leakyrelu_alpha)\n",
    "\n",
    "    def forward(self, input_):\n",
    "        if type(input_) is list:\n",
    "            input_, non_local_graph = input_\n",
    "        else:\n",
    "            non_local_graph = NonLocalGraph(input_, self.near_neigh)\n",
    "\n",
    "        scales = [\n",
    "            self.conv1x1(input_),\n",
    "            self.conv3x3(input_),\n",
    "            self.non_local_aggregation([input_, non_local_graph])\n",
    "        ]\n",
    "        output = torch.mean(torch.stack(scales), dim=0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RW65EnDRoL5"
   },
   "outputs": [],
   "source": [
    "class GraphConvolutionBlock(nn.Module):\n",
    "    def __init__(self, hidden_features, near_neigh, leakyrelu_alpha):\n",
    "        super(GraphConvolutionBlock, self).__init__()\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            GraphConvolution(hidden_features, hidden_features, near_neigh, leakyrelu_alpha),\n",
    "            nn.BatchNorm2d(hidden_features),\n",
    "            nn.LeakyReLU(leakyrelu_alpha)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        return self.output(input_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwRIpa_bPa5Z"
   },
   "source": [
    "Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWVbfLGPPg7n"
   },
   "outputs": [],
   "source": [
    "class GCNNResidualBlock(nn.Module):\n",
    "    def __init__(self, hidden_features, near_neigh, leakyrelu_alpha):\n",
    "        super(GCNNResidualBlock, self).__init__()\n",
    "\n",
    "        self.near_neigh = near_neigh\n",
    "        num_graphconv_blocks = 3\n",
    "\n",
    "        self.blocks = []\n",
    "        for block_num in range(num_graphconv_blocks):\n",
    "            block = GraphConvolutionBlock(\n",
    "                hidden_features, near_neigh, leakyrelu_alpha)\n",
    "            self.blocks.append(block)\n",
    "            self.add_module(f'block_{block_num}', block)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        non_local_graph = NonLocalGraph(input_, self.near_neigh)\n",
    "\n",
    "        output = input_\n",
    "        for block in self.blocks:\n",
    "            output = block([output, non_local_graph])\n",
    "\n",
    "        return input_ + output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L71dn9DbPVbP"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tT3BSI-0PU15"
   },
   "outputs": [],
   "source": [
    "class GCNNPreprocessingBlockSingleScale(nn.Module):\n",
    "    def __init__(self, kernel_size, input_features, hidden_features, near_neigh, leakyrelu_alpha):\n",
    "        super(GCNNPreprocessingBlockSingleScale, self).__init__()\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(input_features, hidden_features, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.LeakyReLU(leakyrelu_alpha),\n",
    "            GraphConvolutionBlock(hidden_features, near_neigh, leakyrelu_alpha)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        return self.output(input_)\n",
    "\n",
    "\n",
    "class GCNNPreprocessingBlock(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, near_neigh, leakyrelu_alpha, kernel_sizes):\n",
    "        super(GCNNPreprocessingBlock, self).__init__()\n",
    "        hidden_features_scale = hidden_features // len(kernel_sizes)\n",
    "\n",
    "        self.scales = []\n",
    "        for kernel_size in kernel_sizes:\n",
    "            scale = GCNNPreprocessingBlockSingleScale(\n",
    "                kernel_size, input_features, hidden_features_scale, near_neigh, leakyrelu_alpha)\n",
    "            self.scales.append(scale)\n",
    "            self.add_module(f'conv{kernel_size}x{kernel_size}', scale)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        scales = [scale(input_) for scale in self.scales]\n",
    "        output = torch.cat(scales, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqrXPpF9PRH5"
   },
   "source": [
    "GCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FytdN8zKPSZW"
   },
   "outputs": [],
   "source": [
    "class GCNN(nn.Module):\n",
    "    def __init__(self, input_features=3, hidden_features=66, near_neigh=8, leakyrelu_alpha=1e-2):\n",
    "        super(GCNN, self).__init__()\n",
    "        \n",
    "        self.name = f'gcnn{hidden_features}'\n",
    "        \n",
    "        num_residual_blocks = 2\n",
    "        kernel_sizes = [3, 5, 7]\n",
    "        num_kernels = len(kernel_sizes)\n",
    "        hidden_features = ((hidden_features + num_kernels - 1) // num_kernels) * num_kernels\n",
    "\n",
    "        self.preprocessing = GCNNPreprocessingBlock(\n",
    "            input_features, hidden_features, near_neigh, leakyrelu_alpha, kernel_sizes)\n",
    "\n",
    "        residual_blocks = []\n",
    "        for _ in range(num_residual_blocks):\n",
    "            residual_blocks.append(GCNNResidualBlock(hidden_features, near_neigh, leakyrelu_alpha))\n",
    "        self.residual_blocks = nn.Sequential(*residual_blocks)\n",
    "\n",
    "        self.output_graph_conv = GraphConvolution(hidden_features, input_features, \n",
    "                                                  near_neigh, leakyrelu_alpha)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        preprocess = self.preprocessing(input_)\n",
    "        residual_blocks = self.residual_blocks(preprocess)\n",
    "        output = self.output_graph_conv(residual_blocks)\n",
    "        return input_ + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_Dn_qirtqFj"
   },
   "outputs": [],
   "source": [
    "def get_gcnn_model(hidden_features=66):\n",
    "    model = GCNN(hidden_features=hidden_features).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxNfewzf0oAC"
   },
   "outputs": [],
   "source": [
    "def test_gcnn():\n",
    "    model = get_gcnn_model()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loader, *_ = TinyImagenetPatchesDenoising(noise_std=0.1).get_loaders(batch_size=8)    \n",
    "    image, target = next(iter(loader))\n",
    "    pred = model(image.to(device))\n",
    "\n",
    "    print('loss=', criterion(pred, target.to(device)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOba6ciBQLzA",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test_gcnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = Path('model')\n",
    "\n",
    "def save_model(model, name):\n",
    "    MODEL_DIR.mkdir(exist_ok=True)\n",
    "    torch.save(model.state_dict(), MODEL_DIR / name)\n",
    "\n",
    "def load_model(model, name):\n",
    "    model.load_state_dict(torch.load(MODEL_DIR / name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KxoI69A36IaN"
   },
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EOmJOwzBQZX"
   },
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion\n",
    "\n",
    "def get_optimizer(model):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrzBCD4n6PW0"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOoXr7CQ0q8A"
   },
   "outputs": [],
   "source": [
    "tiny_imagenet = TinyImagenetPatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0nCmVawA4vT"
   },
   "outputs": [],
   "source": [
    "def train_step(train_loader, model, criterion, optimizer, experiment, epoch):\n",
    "    with experiment.train():\n",
    "        model.train()\n",
    "\n",
    "        tqdm_notebook_train = tqdm_notebook(\n",
    "            train_loader, desc='train loop', leave=False)\n",
    "\n",
    "        for image, target in tqdm_notebook_train:\n",
    "            pred = model(image.to(device))\n",
    "            loss = criterion(pred, target.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            experiment.log_metric(\"loss\", loss.item())\n",
    "\n",
    "            \n",
    "def test_step(test_loader, model, criterion, experiment, epoch):\n",
    "    def _step():\n",
    "        model.eval()\n",
    "\n",
    "        mse_losses = []\n",
    "        tqdm_notebook_test = tqdm_notebook(\n",
    "            test_loader, desc='test loop', leave=False)\n",
    "        for image, target in tqdm_notebook_test:\n",
    "            pred = model(image.to(device))\n",
    "            mse_losses.append(criterion(pred, target.to(device)).item())\n",
    "\n",
    "        experiment.log_metric(\"loss\", np.mean(mse_losses), epoch=epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with experiment.test():\n",
    "            _step()\n",
    "\n",
    "            \n",
    "def validate_step(val_loader, model, criterion, experiment):\n",
    "    def _step():\n",
    "        model.eval()\n",
    "\n",
    "        mse_losses = []\n",
    "        tqdm_notebook_val = tqdm_notebook(\n",
    "            val_loader, desc='val loop', leave=False)\n",
    "        for image, target in tqdm_notebook_val:\n",
    "            pred = model(image.to(device))\n",
    "            mse_losses.append(criterion(pred, target.to(device)).item())\n",
    "\n",
    "        experiment.log_metric(\"loss\", np.mean(mse_losses))\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        with experiment.validate():\n",
    "            _step()\n",
    "\n",
    "\n",
    "def train(get_model, noise_std=0.1, batch_size=48, num_epochs=10, model_name_prefix=''):\n",
    "    train_loader, test_loader, val_loader = \\\n",
    "        TinyImagenetPatchesDenoising(noise_std, tiny_imagenet).get_loaders(batch_size)\n",
    "\n",
    "    model = get_model()\n",
    "    criterion = get_criterion()\n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    experiment = Experiment(**comet_ml_settings)\n",
    "\n",
    "    for epoch in tqdm_notebook(range(num_epochs), desc='Epoch loop'):\n",
    "        train_step(train_loader, model, criterion, optimizer, experiment, epoch)\n",
    "        test_step(test_loader, model, criterion, experiment, epoch)\n",
    "        save_model(model, f'{model.name}_{int(noise_std * 100)}')\n",
    "        if epoch % 10 == 0:\n",
    "            validate_step(val_loader, model, criterion, experiment)\n",
    "\n",
    "    experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "9759b110a5334ee38eb50152268e54dc",
      "3396fd33e9a841dfb27fd3cfe5d6c633",
      "eedd29907d3440fbb29df26faf5bf7e6",
      "3155c86e83ef4e4a863ee63f858b3234",
      "6b3f00c03f58456a96c79ad2bc7182f9",
      "920fddee60df467f8f9d042bbaa731c4",
      "24757698d9114e0a84b4680e0b8cd698",
      "34af78d82e7b4672b4bb20bf644e75f2",
      "a7d903481e0641919c10ce94c31254a7",
      "5e40892ccafe403288acb6079e31a9d1",
      "97b541205cdf48bbb3c7ce60e4656a8a",
      "9f7c9bd1c62b485a960b40a57e5cf18e",
      "3bfd31a2449d48418a882c2c5506ff4c",
      "ec98cda5fa6547c49c0d90289a3f3b74",
      "b9f48fa1c9924db184ec807fe46cd27e",
      "1f0d4da932984b9094487d7f4ae41311"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 988373,
     "status": "error",
     "timestamp": 1579274500832,
     "user": {
      "displayName": "Artem Topilskiy",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDI-avhqJwgahop5KKKRe_5xk0jO9ug8NdpSOxX=s64",
      "userId": "16398220761843505060"
     },
     "user_tz": -180
    },
    "id": "a-a4N4rcuBRS",
    "outputId": "14277102-b3c7-4f35-bf74-7cfb3087f72a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(partial(get_gcnn_model, hidden_features=24),\n",
    "      noise_std=0.1, batch_size=48, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hQ3-tFt0ISNf"
   ],
   "name": "tinyimagenet_gcnn_denoising.ipynb",
   "provenance": [
    {
     "file_id": "1vMwUmKrwOoQ9QwRy4UKBs_PsBAfsyFU9",
     "timestamp": 1575210057221
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f0d4da932984b9094487d7f4ae41311": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24757698d9114e0a84b4680e0b8cd698": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3155c86e83ef4e4a863ee63f858b3234": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34af78d82e7b4672b4bb20bf644e75f2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_24757698d9114e0a84b4680e0b8cd698",
      "value": "  0% 0/6 [00:00&lt;?, ?it/s]"
     }
    },
    "3396fd33e9a841dfb27fd3cfe5d6c633": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34af78d82e7b4672b4bb20bf644e75f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bfd31a2449d48418a882c2c5506ff4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5e40892ccafe403288acb6079e31a9d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b3f00c03f58456a96c79ad2bc7182f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "920fddee60df467f8f9d042bbaa731c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9759b110a5334ee38eb50152268e54dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eedd29907d3440fbb29df26faf5bf7e6",
       "IPY_MODEL_3155c86e83ef4e4a863ee63f858b3234"
      ],
      "layout": "IPY_MODEL_3396fd33e9a841dfb27fd3cfe5d6c633"
     }
    },
    "97b541205cdf48bbb3c7ce60e4656a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "train loop",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec98cda5fa6547c49c0d90289a3f3b74",
      "max": 6250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bfd31a2449d48418a882c2c5506ff4c",
      "value": 3159
     }
    },
    "9f7c9bd1c62b485a960b40a57e5cf18e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f0d4da932984b9094487d7f4ae41311",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b9f48fa1c9924db184ec807fe46cd27e",
      "value": " 51% 3159/6250 [53:24&lt;52:12,  1.01s/it]"
     }
    },
    "a7d903481e0641919c10ce94c31254a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97b541205cdf48bbb3c7ce60e4656a8a",
       "IPY_MODEL_9f7c9bd1c62b485a960b40a57e5cf18e"
      ],
      "layout": "IPY_MODEL_5e40892ccafe403288acb6079e31a9d1"
     }
    },
    "b9f48fa1c9924db184ec807fe46cd27e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec98cda5fa6547c49c0d90289a3f3b74": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eedd29907d3440fbb29df26faf5bf7e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch loop",
      "description_tooltip": null,
      "layout": "IPY_MODEL_920fddee60df467f8f9d042bbaa731c4",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b3f00c03f58456a96c79ad2bc7182f9",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
